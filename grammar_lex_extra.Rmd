## Extra analyses/plots that are not in the paper

Using Age and Vocab to predict Morphology and Syntax Scores.
```{r, fig.width=12, fig.height=8}
#quartz(width=8,height=7.5)
#ggplot(ms, aes(x = vocab.mean, y = score, colour = age.group, fill = age.group,
#               label = age.group)) + 
# ggplot(ms, aes(x = vocab.mean, y = score, colour = age.bin, fill = age.bin,
#                label = age.bin)) + 
#   #geom_point(alpha=.5, size=.8) + 
#   geom_jitter(alpha=.6, ssize=.8) +
#   geom_smooth(method="lm", formula = y ~ I(x^2) - 1) + 
#   facet_grid(language~measure) + 
#   scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.1),
#                      name = "Vocabulary Size") + 
#   scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
#                      "Score (Mean Items)") + 
#   theme_bw(base_size = 14) +
#   scale_color_brewer(palette="Set1") +
#   scale_fill_brewer(palette="Set1") 
```

Plot vocabulary composition by language.
```{r, fig.width=10, fig.height=8}
# ggplot(filter(summary.vocab.comp,lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour=lexical_category, 
#            shape = lexical_category, fill = lexical_category,
#            label=lexical_category)) +
#   geom_point(size = 1, alpha = 0.25) +
#   facet_wrap(~ language) +
#   geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of total vocabulary") +
#   scale_x_continuous(name = "Vocabulary Size") +
#   geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Spectral") +
#   scale_fill_brewer(palette = "Spectral")+
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="none",
#         text = element_text(family=font))
```

Plot vocabulary composition by language and age group.
```{r, fig.width=10, fig.height=8}
# ggplot(filter(summary.vocab.comp,lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour=lexical_category, 
#            shape = lexical_category, fill = lexical_category,
#            label = lexical_category)) +
#   geom_jitter(size = 1, alpha = 0.5) +
#   facet_grid(language ~ age.group) +
#   geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of total vocabulary") +
#   scale_x_continuous(name = "Vocabulary Size") +
#   geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1") +
#   scale_fill_brewer(palette = "Set1")+
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="none")
```

Plot vocabulary composition by language, split by age group.
```{r, fig.width=10, fig.height=8}
#quartz(width=7, height=6)
# ggplot(filter(summary.vocab.comp, lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour=age.group, linetype = lexical_category)) +
# #  geom_jitter(size = 1, alpha = 0.5) +
#   facet_wrap(~ language) +
#   geom_hline(data=lang.vocab.comp, 
#              aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(method='loess', span=.5) +
#   scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.2),
#                      name = "Vocabulary Size") + 
#   scale_y_continuous(limits = c(0, .6), breaks = seq(0,1,.2),
#                      "Proportion of total vocabulary") + 
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1", name = "Age Group (months)") +
#   scale_fill_brewer(palette = "Set1") +
#   scale_linetype(name = "Lexical Category") +
#   theme(#axis.text.x = element_text(angle=-40, hjust = 0),
# #        axis.title.y = element_text(vjust=0.35),
# #        axis.title.x = element_text(vjust=-0.5),
#         legend.position="bottom")
#ggsave(file=("age_composition.pdf"), width=7, height=6)
```

Plot vocabulary composition by language and lexical category.
```{r, fig.width=10, fig.height=8}
#quartz(width=8, height=6)
# ggplot(filter(summary.vocab.comp, lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour = age.group, fill = age.group)) +
# #  geom_jitter(size = 1, alpha = 0.5) +
#   facet_grid(language ~ lexical_category) +
#   geom_hline(data=lang.vocab.comp, 
#              aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(aes(group=age.group), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of total vocabulary") +
#   scale_x_continuous(name = "Vocabulary Size") +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1") +
#   scale_fill_brewer(palette = "Set1")+
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="none")
#ggsave(file=("age_composition.pdf"), width=8, height=6)
```

Use Age and Lexical Category Score to predict Morphology and Syntax Scores, for each lexical category.
```{r}
# plot.vocab.comp.prediction <- function(category) {
#   p <- ggplot(filter(prop.comp, lexical_category==category),
#               aes(x = cdi.prop, y = score, colour = age.group, fill = age.group,
#                   label = age.group)) + 
#         #geom_point(alpha=.5, size=.8) + 
#     geom_jitter(alpha=.5,size=.8) +
#     geom_smooth(method="lm", formula = y ~ I(x^2) - 1) + 
#     facet_grid(language ~ measure) + 
#     scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.1),
#                        name = "Category Size") + 
#     scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
#                        "Score (Mean Items)") + 
#     theme_bw(base_size = 14) +
#     ggtitle(category) +
#     scale_color_brewer(palette="Set1") +
#     scale_fill_brewer(palette="Set1") 
#   
#   return(p)
# }
```

Plot grammar score prediction using Nouns.
```{r, fig.width=10, fig.height=8}
#plot.vocab.comp.prediction("Nouns")
```

Plot grammar score prediction using Predicates.
```{r, fig.width=10, fig.height=8}
#plot.vocab.comp.prediction("Predicates")
```

Plot grammar score prediction using Function Words.
```{r, fig.width=10, fig.height=8}
#plot.vocab.comp.prediction("Function Words")
```

Fit models to vocab composition data.
```{r}
# comp.lm <- function(lang) {
#   
#   prop.comp.lang <- filter(prop.comp, language == lang, lexical_category != "Other")
#   comp.age.lm <- lm(cdi.prop ~ lexical_category : I((vocab.mean*100)^2):age.group +
#                            lexical_category : I((vocab.mean*100)):age.group + 0,
#                          data=prop.comp.lang)
#   comp.noage.lm <- lm(cdi.prop ~ lexical_category : I((vocab.mean*100)^2) + 
#                            lexical_category : I((vocab.mean*100)) + 0,
#                          data=prop.comp.lang)
#   prop.comp.lang$age.predict <- predict.lm(comp.age.lm)
#   prop.comp.lang$noage.predict <- predict.lm(comp.noage.lm)
#   prop.comp.lang$language <- lang
#   return(prop.comp.lang)
#   }
# 
# comp.english <- comp.lm("English")
# comp.spanish <- comp.lm("Spanish")
# comp.norweigian <- comp.lm("Norwegian")
# comp.danish <- comp.lm("Danish")
# 
# comp.all <- rbind(comp.english, comp.spanish, comp.norweigian, comp.danish) %>%
#   mutate(language = factor(language,
#                            levels = c("English", "Spanish", "Norwegian", "Danish")))
```

Plot predictions of model with age.
```{r, fig.width=10, fig.height=6}
#quartz(width=10, height=6)
# ggplot(comp.all,
#        aes(x=vocab.mean, y=cdi.prop, colour=age.group, linetype=lexical_category)) +
# #       aes(x=vocab.mean, y=cdi.prop, colour=lexical_category, 
# #           shape=lexical_category, fill=lexical_category,
# #           label=lexical_category)) +
# #  geom_jitter(size=0.7, alpha=0.2, pch="o") +
#   geom_line(aes(y = age.predict)) +
#   facet_wrap(~language) +
# #  geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
# #             linetype="dashed", color="grey") + #baselines for each language
#   #geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of CDI Category") +
#   scale_x_continuous(name = "Vocabulary Size") +
# #  geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1", name = "Age Group (months)") +
#   scale_linetype(name = "Lexical Category") +
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="right")
#ggsave(file=("composition_model_age_points.png"), width=10, height=6)
```

Plot predictions of model without age.
```{r, fig.width=10, fig.height=8}
#quartz(width=10, height=6)
# ggplot(comp.all,
#        aes(x=vocab.mean, y=cdi.prop, colour=age.group, linetype=lexical_category)) +
# #       aes(x=vocab.mean, y=cdi.prop, colour=lexical_category, 
# #           shape=lexical_category, fill=lexical_category,
# #           label=lexical_category)) +
# #  geom_jitter(size=0.7, alpha=0.2, pch="o") +
#   geom_line(aes(y = noage.predict)) +
#   facet_wrap(~language) +
# #  geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
# #             linetype="dashed", color="grey") + #baselines for each language
#   #geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of CDI Category") +
#   scale_x_continuous(name = "Vocabulary Size") +
# #  geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1", name = "Age Group (months)") +
#   scale_linetype(name = "Lexical Category") +
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="right")
#ggsave(file=("composition_model_age_points.png"), width=10, height=6)
```

Compute (vocab x age) interaction coefficients for each lexical category and language.
```{r}
# quad.mod.coef.fun <- function(cdi.prop, vocab.mean, age) {
#   return(coef(lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0))["I((vocab.mean * 100))^2:age"])
#   }
# 
# quad.mod.se.fun <- function(cdi.prop, vocab.mean, age) {
#   return(summary(lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0))$coefficients["I((vocab.mean * 100))^2:age", "Std. Error"])
#   }
# 
# compute.model <- function(cdi.prop, vocab.mean, age) {
#   return(lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0))
# }
# 
# #comp.coefs <- prop.comp %>% 
# #  group_by(language, lexical_category) %>%
# #  do(model = lm(.$cdi.prop ~ I((.$vocab.mean*100)^2) * .$age + 
# #                  I(.$vocab.mean*100) + 0)[[1]]) %>%
# #  mutate(coef = coef(model)["I((.$vocab.mean * 100)^2):.$age"],
# #         s = summary(model)$coefficients),
# #         se = summary(model)$coefficients["I((.$vocab.mean * 100)^2):.$age", "Std. Error"])
# 
# comp.coefs <- prop.comp %>%
#   group_by(language, lexical_category) %>%
#   summarise(#coef = coef(model)["I((vocab.mean * 100)^2):age"]),
#             #se = summary(model)$coefficients["I((vocab.mean * 100)^2):age", "Std. Error"])
#             coef = mod.coef.fun(cdi.prop, vocab.mean, age),
#             se = mod.se.fun(cdi.prop, vocab.mean, age))
# 
# #linear(vocab)
# #linear(vocab)*age
# #linear(vocab)*age + quadratic(vocab)
# #linear(vocab)*age + quadratic(vocab)*age
# #linear(vocab) + quadratic(vocab)*age
# 
# model1 <- lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) * age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model2 <- lm(cdi.prop ~ I((vocab.mean*100)^2) + I(vocab.mean*100) * age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model3 <- lm(cdi.prop ~ I((vocab.mean*100)^2)*age + I(vocab.mean*100) + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model4 <- lm(cdi.prop ~ I((vocab.mean*100)^2) + I(vocab.mean*100) + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model5 <- lm(cdi.prop ~ I((vocab.mean*100)^2)*age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model6 <- lm(cdi.prop ~ I((vocab.mean*100)^2):age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
```

Plot coefficients for each language.
```{r}
#quartz(width=6, height=4)
# ggplot(comp.coefs, 
#        aes(x=language, y=coef, fill=lexical_category)) + 
#   geom_bar(position="dodge", stat="identity") + 
#   geom_linerange(aes(ymin=coef-se, ymax=coef+se), 
#                  position = position_dodge(width=.9)) +
#   ylab("Age interaction coefficient") + 
#   xlab("Language") +
#   theme(legend.position = "bottom") +
#   theme_bw(base_size = 14) +
#   scale_fill_brewer(palette = "Set1",
#                     name="")
#ggsave(file=("coeffs.pdf"), width=6, height=4)
```

Plot noun/verb composition.
```{r, fig.width=10, fig.height=8}
#quartz(width=8, height=6)
# ggplot(prop.noun.verb, aes(x=vocab.mean, y=pos.prop, colour=pos, label=pos)) +
#   geom_jitter(alpha=0.17, size=0.75) +
#   facet_wrap(~ language) +
#   geom_smooth(aes(group=pos), method='loess', span=0.5) +
#   scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
#                      name = "Proportion of Part of Speech") +
#   scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.1),
#                      name = "Vocabulary Size") +
#   theme_bw(base_size=11) + 
#   scale_color_brewer(palette = "Set1", name = "Lexical Category") +
#   theme(legend.position = c(0.09,0.92),
#         legend.text = element_text(size=9),
#         legend.title = element_text(size=9),
#         legend.key.height = unit(0.9, "char"),
#         legend.key.width = unit(0.4, "cm"),
#         legend.key = element_blank(),
#         legend.background = element_rect(fill="transparent"))
#ggsave(file=("~/Documents/projects/wordbank_nsf/figures/composition.png"), width=8, height=6, dpi=500)
```

Function for getting word-level difference between simple/complex forms an item.
```{r}
# complexity.diff <- function(item) {
#   
#   if(length(grep("/", item)) == 0) {return(item)}
#   else{
#     phrases <- str_split(item," / ")[[1]]
#     first.phrase <- str_split(phrases[1], " ")[[1]]
#     second.phrase <- str_split(phrases[2], " ")[[1]]
#   
#     first.diff <- setdiff(first.phrase,second.phrase)
#     second.diff <- setdiff(second.phrase,first.phrase)
#   
#     if(length(first.diff)==0) return(paste(second.diff,collapse=" ")) 
#     else if(length(second.diff)==0) return(paste(first.diff,collapse=" "))
#     else{first.phrase = paste(first.diff, collapse =" ")
#          second.phrase = paste(second.diff,collapse = " ")
#          return(paste(first.phrase, second.phrase ,sep=" / "))}
#     }
#   }
```

Fit quadratic models to grammar data and get their predictions.
```{r}
# lm.predicted.data <- filter(ms, !is.na(score))
# lm.predicted.data$predicted <- NA
# 
# for (lang in c("English", "Spanish", "Norwegian", "Danish")) {
#     model <- lm(score ~ I((vocab.mean*100)^2) * age.group * measure + I(vocab.mean*100),
#                 data = filter(lm.predicted.data, language==lang))
#     predict <- inv.logit(predict.lm(model, lm.predicted.data[lm.predicted.data$language==lang,]))
#     print(cor.test(predict, lm.predicted.data[lm.predicted.data$language==lang,]$score))
#     lm.predicted.data[lm.predicted.data$language==lang,]$predicted <- predict
# }

# mod.coef.fun <- function(score, vocab.mean, age) {
#   return(coef(lm(score ~ I((vocab.mean * 100)^2) * age + I(vocab.mean * 100) + 0))["I((vocab.mean * 100)^2):age"])
#   }
# 
# mod.rsq.fun <- function(score, vocab.mean, age) {
#   return(summary(lm(score ~ I((vocab.mean * 100)^2) * age + I(vocab.mean * 100) + 0))$adj.r.squared)
#   }
# 
# mod.se.fun <- function(score, vocab.mean, age) {
#   return(summary(lm(score ~ I((vocab.mean*100)^2) * age + I(vocab.mean * 100) + 0))$coefficients["I((vocab.mean * 100)^2):age",
#                                                                            "Std. Error"])
#   }

# grammar.coefs <- ms %>% 
#   group_by(language, measure) %>%
#   summarise(coef = mod.coef.fun(score, vocab.mean, age),
#             se = mod.se.fun(score,vocab.mean,age),
#             rsq = mod.rsq.fun(score,vocab.mean,age))
# grammar.coefs$language = factor(grammar.coefs$language, levels=c("Norwegian", "English",
#                                                                  "Danish", "Spanish"))
```

Fit a bunch of models to grammar data and do model comparison.
```{r}
# linear <- formula(score ~ I(vocab.mean*100))
# quadratic <- formula(score ~ I((vocab.mean*100)^2))
# linear.quadratic <- formula(score ~ I((vocab.mean*100)^2) + I(vocab.mean*100))
# linear.quadratic.age <- formula(score ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100))
# linear.quadratic.age.noint <- formula(score ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0)
# grammar.formulas <- c(linear, quadratic, linear.quadratic,
#                       linear.quadratic.age, linear.quadratic.age.noint)
# 
# grammar.models <- ms %>%
#   group_by(language, measure) %>%
#   do(linear = lm(grammar.formulas[[1]], .),
#      quadratic = lm(grammar.formulas[[2]], .),
#      linear.quadratic = lm(grammar.formulas[[3]], .),
#      linear.quadratic.age = lm(grammar.formulas[[4]], .),
#      linear.quadratic.age.noint = lm(grammar.formulas[[5]], .)) %>%
#   mutate(linear_rsq = summary(linear)$adj.r.squared,
#          quadratic_rsq = summary(quadratic)$adj.r.squared,
#          linear.quadratic_rsq = summary(linear.quadratic)$adj.r.squared,
#          linear.quadratic.age_rsq = summary(linear.quadratic.age)$adj.r.squared,
#          linear.quadratic.age.noint_rsq = summary(linear.quadratic.age.noint)$adj.r.squared)
# 
# grammar.anovas <- grammar.models %>%
#   do(linear_quadratic_anova = anova(.$linear,
#                                     .$quadratic),
#      quadratic_linear.quadratic_anova = anova(.$quadratic,
#                                               .$linear.quadratic),
#      linear.quadratic_linear.quadratic.age_anova = anova(.$linear.quadratic,
#                                                          .$linear.quadratic.age),
#      linear.quadratic.age_linear.quadratic.age.noint_anova = anova(.$linear.quadratic.age,
#                                                                    .$linear.quadratic.age.noint))
# 
# grammar.p_values <- grammar.anovas %>%
#   do(linear_quadratic_p = .$linear_quadratic_anova$`Pr(>F)`[[2]],
#      quadratic_linear.quadratic_p = .$quadratic_linear.quadratic_anova$`Pr(>F)`[[2]],
#      linear.quadratic_linear.quadratic.age_p =
#        .$linear.quadratic_linear.quadratic.age_anova$`Pr(>F)`[[2]],
#      linear.quadratic.age_linear.quadratic.age.noint_p =
#        .$linear.quadratic.age_linear.quadratic.age.noint_anova$`Pr(>F)`[[2]]) %>%
#   mutate(linear_quadratic_p = log10(linear_quadratic_p[[1]]),
#          quadratic_linear.quadratic_p = log10(quadratic_linear.quadratic_p[[1]]),
#          linear.quadratic_linear.quadratic.age_p =
#            log10(linear.quadratic_linear.quadratic.age_p[[1]]),
#          linear.quadratic.age_linear.quadratic.age.noint_p =
#            log10(linear.quadratic.age_linear.quadratic.age.noint_p[[1]]))
```

Show R-squared values of some models.
```{r,results = 'asis'}
# display.models <- grammar.models %>% select(language, measure, linear.quadratic_rsq,
#                                             linear.quadratic.age_rsq, linear.quadratic.age.noint_rsq)
# kable(display.models)
```

Show the log p-values of the anova of successive pairs of models.
```{r,results = 'asis',cache=FALSE}
# grammar.p_values$language = grammar.models$language
# grammar.p_values$measure = grammar.models$measure
# grammar.p_values <- grammar.p_values[,c(5,6,1:4)]
# display.p_values <- grammar.p_values %>% select(language, measure, linear.quadratic_linear.quadratic.age_p, linear.quadratic.age_linear.quadratic.age.noint_p)
# kable(display.p_values)
```

Compute (vocab x age) interaction terms for each wordform and complexity item.
```{r,fig.height=5,fig.width=8}
#compute interaction terms each item
# i.coef.function <- function(data, item.definition) {
#   return(coef(glm(cbind(sum,diff) ~ vocab.mean + age,
#               data=filter(data, definition==item.definition),
#               family="binomial"))["age"][[1]])
# #  return(coef(lm(value ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0,
# #              data=filter(data, definition==item.definition)))["I((vocab.mean * 100)^2):age"][[1]])
#   }
# 
# i.se.function <- function(data, item.definition) {
#   return(summary(lm(value ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0,
#                     data=filter(data, definition==item.definition)))$coefficients["I((vocab.mean * 100)^2):age", "Std. Error"])
#   }
# 
# lang.interaction.terms <- function(grammar.by.item) {
#   
#   ctype.interaction.terms <- function(ctype) {
#     
#     if(ctype %in% grammar.by.item$coded.type) {
#       
#       ctype.data <- filter(grammar.by.item, coded.type==ctype)
#       ctype.coef <- sapply(unique(ctype.data$definition),
#                             function(definition) i.coef.function(ctype.data, definition))
#       ctype.se <- sapply(unique(ctype.data$definition),
#                             function(definition) i.se.function(ctype.data, definition))
#       
#       ctype.terms <- data.frame(coded.type = ctype,
#                                 definition = names(ctype.coef),
#                                 coef = ctype.coef,
#                                 se = ctype.se,
#                                 row.names=NULL) %>%
#         rename(item = definition)
#       ctype.terms$coded.type <- factor(ctype.terms$coded.type, levels = c("word_form", "morphology", "syntax"),
#                                        labels = c("Word Form", "Complexity (Morphological)", "Complexity (Syntactic)"))
#       
#       return(ctype.terms)
#       }
#     }
#   
#   wordform.terms <- ctype.interaction.terms("word_form")
#   morphology.terms <- ctype.interaction.terms("morphology")
#   syntax.terms <- ctype.interaction.terms("syntax")
#   
#   lang.terms <- rbind_list(wordform.terms, morphology.terms, syntax.terms) %>%
#     arrange(coef) %>%
#     mutate(item = factor(item, levels=item))    
#   
#   return(lang.terms)
#   
#   }
```

Compute coefficients of noun/verb models.
```{r}
#TODO: model comparison
#prop.mod.coef.fun <- function(pos.prop, vocab.mean, age) {
#  return(coef(lm(pos.prop ~ I((vocab.mean*100)^2) + I(vocab.mean*100) * age + 0))["I(vocab.mean * 100):age"])
#  return(coef(glm(pos.prop ~ I(vocab.mean*100) * age + 0,
#                  family="binomial"))["I(vocab.mean * 100):age"])
#  }

# prop.mod.rsq.fun <- function(pos.prop, vocab.mean, age) {
#   return(summary(glm(pos.prop ~ I(vocab.mean*100) * age + 0,
#                   family="binomial"))$adj.r.squared)
#   }

# prop.mod.se.fun <- function(pos.prop, vocab.mean, age) {
#   return(summary(glm(pos.prop ~ I(vocab.mean*100) * age + 0,
#                      family="binomial"))$coefficients["I(vocab.mean * 100):age", "Std. Error"])
#   }

#TODO: what metric to use instead of r-squared?
# noun.verb.coefs <- prop.noun.verb %>%
#   group_by(language, pos) %>%
#   summarise(coef = prop.mod.coef.fun(pos.prop, vocab.mean, age),
#            rsq = prop.mod.rsq.fun(pos.prop, vocab.mean, age),
#            se = prop.mod.se.fun(pos.prop, vocab.mean, age))
```

Fit mixed-effects models of kid-word production.
```{r}
# d.vocab <- language.vocab.sizes(d.english)
#  d.english.vocab <- left_join(d.english, d.vocab) %>%
#    filter(age >= 16, age <= 30) %>%
#    rowwise() %>%
#    mutate(pos = get.pos(lexical_category, category)) %>%
#    filter(pos != "other") %>%
#    mutate(produces = value=="produces")
# 
# #TODO: models that converge
# big.lm.nouns <- glmer(produces ~ vocab.mean*age + 0 + (1|item),
#                       family="binomial",
#                       data=filter(d.english.vocab,pos=="nouns"))
# 
# big.lm.verbs <- glmer(produces ~ vocab.mean*age + 0 + (1|item),
#                       family="binomial",
#                       data=filter(d.english.vocab,pos=="verbs"))
# 
# vehicle.lm <- glmer(produces ~ vocab.mean*age + 0 + (1|item), family="binomial",
#                    data=filter(d.english.vocab,pos=="nouns",category=="vehicles"))
#  
# big.lm.verbs <- glmer(produces ~ I(vocab.mean*100)*age + 0 + (1|id) + (1|item), family="binomial",
#                       data=filter(d.english.vocab,pos=="verbs"))
```

Re-compute vocab composition in terms of nouns and verbs.
```{r}
get.pos <- function(lex_cat, cat) {
  if(lex_cat == "nouns"){
    return("nouns")
    } else if (cat == "action_words"){
      return("verbs")
      } else {
        return("other")
        }
  }

noun.verb.comp <- function(lang.data,lang) {  
    
  lang.data <- lang.data %>%
    rowwise() %>%
    mutate(pos = get.pos(lexical_category, category))
  
  d.vocab <- language.vocab.sizes(lang.data)
  
  d.pos <- lang.data %>%
    filter(type == "word") %>%
    group_by(id, pos) %>%
    summarise(pos.size = sum(value == "produces", na.rm=TRUE))
  
  d.vocab.comp <- left_join(d.vocab, d.pos)
  d.vocab.comp$language = lang
  
  return(d.vocab.comp)
  }

# get data for kids in each language
noun.verb.english <- noun.verb.comp(d.english,"English")
noun.verb.spanish <- noun.verb.comp(d.spanish,"Spanish")
noun.verb.norwegian <- noun.verb.comp(d.norwegian,"Norwegian")
noun.verb.danish <- noun.verb.comp(d.danish,"Danish")

summary.noun.verb <- rbind_list(noun.verb.english, noun.verb.spanish,
                                 noun.verb.norwegian, noun.verb.danish) %>%
  mutate(language = factor(language,
                           levels = c("English", "Spanish", 
                                      "Norwegian", "Danish")),
         pos = factor(pos, 
                      levels = c("nouns", "verbs", "other"),
                      labels = c("Nouns", "Verbs", "Other")))
summary.noun.verb <- left_join(ms, summary.noun.verb) %>%
  filter(pos != "Other")

get.lang.noun.verb <- function(lang.items) {  
  
  lang.words <- lang.items %>%
    filter(form == "WS", type=="word") %>%
    rowwise() %>%
    mutate(pos = get.pos(lexical_category, category))
  
  lang.noun.verb <- lang.words %>%
    group_by(language, pos) %>%
    summarise(num.per.pos = n())
    
  return(lang.noun.verb)
  
  }

lang.noun.verb <- get.lang.noun.verb(items)
lang.noun.verb %<>%
  ungroup() %>%
  mutate(language = factor(language,
                           levels = c("English", "Spanish", 
                                      "Norwegian", "Danish")),
         pos = factor(pos, 
                      levels=c("nouns", "verbs", "other"),
                      labels=c("Nouns", "Verbs", "Other"))) %>%
  filter(pos != "Other")

prop.noun.verb <- left_join(summary.noun.verb, lang.noun.verb) %>%
  mutate(pos.prop = pos.size / num.per.pos)

prop.noun.verb.diff <- left_join(summary.noun.verb, lang.noun.verb) %>%
  rowwise() %>%
  mutate(pos.unknown = num.per.pos - pos.size)

noun.binomial <- glm(cbind(pos.size, pos.unknown) ~ vocab.mean + age,
                        data = filter(prop.noun.verb.diff, language=="Spanish",
                                      pos=="Nouns"),
                        family = "binomial")
verb.binomial <- glm(cbind(pos.size, pos.unknown) ~ vocab.mean + age,
                        data = filter(prop.noun.verb.diff, language=="Spanish",
                                      pos=="Verbs"),
                        family = "binomial")
#test.binomial.danish <- with(filter(prop.noun.verb.diff,language=="Danish"),
#                      glm(cbind(pos.size,pos.unknown) ~ I(100*vocab.mean)*age*pos + 0,family = "binomial"))
```

Compute coefficients of noun/verb models.
```{r}
noun.verb.models <- prop.noun.verb.diff %>%
  filter(!is.na(sum)) %>%
  group_by(language, pos) %>%
  do(model.vocab = glm(cbind(pos.size,pos.unknown) ~ vocab.mean, data = .,
                       family="binomial"),
     model.vocab.age = glm(cbind(pos.size,pos.unknown) ~ vocab.mean + age, data = .,
                           family="binomial")) %>%
  mutate(AIC.vocab = AIC(model.vocab),
         AIC.vocab.age = AIC(model.vocab.age),
         deltaAIC = AIC.vocab - AIC.vocab.age,
         age.coef = coef(model.vocab.age)["age"],
         age.se = se.coef(model.vocab.age)["age"])

noun.verb.models$language <- factor(noun.verb.models$language, levels = c("Norwegian",
                                                                          "English",
                                                                          "Danish",
                                                                          "Spanish"))
```

Plot noun/verb coefficients.
```{r}
#quartz(width=6, height=4)
ggplot(noun.verb.models, 
       aes(x=language, y=age.coef, fill=pos)) + 
  geom_bar(position="dodge", stat="identity") + 
#  geom_text(aes(label=paste(expression("R^2=="),round(rsq,2)), y=1.5e-7),
#            position = position_dodge(width=0.9),
#            size = 2.5, parse = TRUE) +
  geom_linerange(aes(ymin=age.coef-age.se, ymax=age.coef+age.se), 
                 position = position_dodge(width=.9)) +
  ylab("Age effect coefficient") + 
  xlab("Language") +
  theme_bw(base_size = 14) +
  scale_fill_brewer(palette = "Set2",
                    name = "") +
  theme(legend.position = c(0.07,0.95),
        legend.text = element_text(size=10),
        legend.key.height = unit(0.9, "char"),
        legend.key.width = unit(0.4, "cm"),
        legend.key = element_blank(),
        legend.background = element_rect(fill="transparent"),
        text = element_text(family=font))
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/coefs_noun_verb.png"), width=6, height=4)
```

Plot vocabulary composition by language.
```{r, fig.width=10, fig.height=2.9}
#quartz(width=10, height=2.9)
ggplot(filter(prop.comp, lexical_category != "Other"),
       aes(x=vocab.mean, y=cdi.prop, colour=lexical_category,
           label=lexical_category)) +
  geom_jitter(alpha=0.15, size=.75) +
  facet_wrap(~ language, nrow = 1, ncol = 4,) +
  geom_smooth(aes(group=lexical_category),
              method='loess', span=0.5, size=0.65, fill=NA) +
  scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
                     name = "Proportion of CDI Category") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.2),
                     name = "Vocabulary Size") +
  theme_bw(base_size=12) + 
  theme(legend.position = c(0.06,0.82),
        legend.text = element_text(size=8),
        legend.title = element_text(size=9),
        legend.key.height = unit(0.9, "char"),
        legend.key.width = unit(0.3, "cm"),
        legend.key = element_blank(),
        legend.background = element_rect(fill="transparent"),
        text = element_text(family=font)) +
  scale_color_brewer(palette = "Set2", name = "Lexical Category")
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/composition.png"), width=10, height=2.9, dpi=300)
```

Model testing out zone of madness o_O
```{r}
# tmp.data <- filter(ms, language=="English",measure=="Complexity",!is.na(score))
# tmp.data2 <- filter(ms, language=="English",measure=="Word Form",!is.na(score))
# 
# tmp.data.all <-  filter(ms, language=="English",!is.na(sum))
# 
# eng.data.cmp <- filter(ms, language=="English",!is.na(sum),measure=="Complexity")
# eng.data.wf <- filter(ms, language=="English",!is.na(sum),measure=="Word Form")
# 
# cmp.lm1 <- glm(cbind(sum,diff) ~ vocab.mean,
#                          data = eng.data.cmp,family="binomial")
# 
# cmp.lm3 <- glm(cbind(sum,diff) ~ age,
#                          data = eng.data.cmp,family="binomial")
# 
# cmp.lm2 <- glm(cbind(sum,diff) ~ vocab.mean + age,
#                          data = eng.data.cmp,family="binomial")
# 
# eng.data.cmp$predicted1 <- inv.logit(predict.lm(cmp.lm1))
# eng.data.cmp$predicted2 <- inv.logit(predict.lm(cmp.lm2))
# eng.data.cmp$predicted3 <- inv.logit(predict.lm(cmp.lm3))
# 
# cor(eng.data.cmp$mean,eng.data.cmp$predicted2)
# cor(eng.data.cmp$mean,eng.data.cmp$predicted1)
# 
# cmp.models <- AIC(cmp.lm1, cmp.lm2, cmp.lm3)
# cmp.models$formula <- c(cmp.lm1$formula, cmp.lm2$formula, cmp.lm3$formula)
# cmp.models %<>%
#   mutate(delta.AIC = AIC - min(cmp.models$AIC),
#          akaike.weight = exp(-delta.AIC/2))
# 
# 
# wf.lm1 <- glm(cbind(sum,diff) ~ vocab.mean,
#                          data = eng.data.wf,family="binomial")
# 
# 
# wf.lm3 <- glm(cbind(sum,diff) ~ age,
#                          data = eng.data.wf,family="binomial")
# 
# wf.lm2 <- glm(cbind(sum,diff) ~ vocab.mean + age,
#                          data = eng.data.wf,family="binomial")
# 
# eng.data.wf$predicted1 <- inv.logit(predict.lm(wf.lm1))
# eng.data.wf$predicted2 <- inv.logit(predict.lm(wf.lm2))
# eng.data.wf$predicted3 <- inv.logit(predict.lm(wf.lm3))
# 
# cor(eng.data.wf$mean,eng.data.wf$predicted2)-cor(eng.data.wf$mean,eng.data.wf$predicted1)
# 
# wf.models <- AIC(wf.lm1, wf.lm2, wf.lm3)
# wf.models$formula <- c(wf.lm1$formula, wf.lm2$formula, wf.lm3$formula)
# wf.models %<>%
#   mutate(delta.AIC = AIC - min(wf.models$AIC),
#          akaike.weight = exp(-delta.AIC/2))
# 
# 
# 
# 
# english.grammar.lm2s <- glm(cbind(sum,diff) ~ (vocab.mean+age+measure)^2,
#                          data = tmp.data.all,family="binomial")
# 
# 
# english.grammar.lm <- glm(cbind(sum,diff) ~ vocab.mean*age.group*measure,
#                          data = tmp.data.all,family="binomial")
# 
# english.grammar.lm2 <- glm(cbind(sum,diff) ~ vocab.mean*age*measure,
#                          data = tmp.data.all,family="binomial")
# 
# english.grammar.lm3 <- glm(cbind(sum,diff) ~ I((vocab.mean*100)^2)*measure+age*measure,
#                          data = tmp.data.all,family="binomial")
# 
# 
# comp.lm.1 <- glm(cbind(sum,diff) ~ vocab.mean,
#                          data = filter(tmp.data.all,measure == "Complexity"),family="binomial")
# 
# comp.lm.2 <- glm(cbind(sum,diff) ~ vocab.mean + age,
#                          data = filter(tmp.data.all,measure =="Complexity"),family="binomial")
# 
# wf.lm.1 <- glm(cbind(sum,diff) ~ vocab.mean,
#                          data = filter(tmp.data.all,measure =="Word Form"),family="binomial")
# 
# wf.lm.2 <- glm(cbind(sum,diff) ~ vocab.mean + age,
#                          data = filter(tmp.data.all,measure =="Word Form"),family="binomial")
# 
# 
# 
# english.grammar.lm3 <- glm(cbind(sum,diff) ~ I((vocab.mean*100)^2)*measure+age*measure,
#                          data = tmp.data.all,family="binomial")
# 
# s
# english.grammar.lm3 <- glm(cbind(sum,diff) ~ vocab.mean*age + vocab.mean*measure + measure*age,
#                          data = tmp.data.all,family="binomial")
# 
# english.grammar.lm3 <- glm(cbind(sum,diff) ~ vocab.mean*age + vocab.mean*measure + measure*age,
#                          data = tmp.data.all,family="binomial")
# 
# tmp.data.all$predicted = inv.logit(predict.lm(english.grammar.lm))
# 
# 
# cor.test(tmp.data.all$predicted.group,tmp.data.all$score)
# 
# ggplot(tmp.data.all, aes(x = vocab.mean, y = score, 
#                            colour = age.group, fill = age.group,
#                            label = age.group, group=interaction(age.group,measure))) + 
#   geom_jitter(alpha=.8, size=2) +
#   geom_line(aes(y=predicted),size=0.65) + 
#   facet_grid(measure~.) + 
#   scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.2),
#                      name = "Vocabulary Size") + 
#   scale_y_continuous(limits = c(0,1), breaks = seq(0,1,.25),
#                      "Score (Mean Items)") + 
#   theme_bw(base_size = 11) +
#   theme(legend.position = c(0.06,0.912),
#         legend.text = element_text(size=6),
#         legend.title = element_text(size=6),
#         legend.key.height = unit(0.75, "char"),
#         legend.key.width = unit(0.4, "cm"),
#         legend.key = element_blank(),
#         legend.background = element_rect(fill="transparent"),
#         text=element_text(family=font)) +
#   scale_color_brewer(type="div", palette=9,
#                      name="Age Group\n (months)") +
# #                     labels=c("16-19","20-23","24-27","28-31")) +
#   scale_fill_brewer(palette = "Spectral",
#                     guide=FALSE)
# 
# 
# english.grammar.lm2 <- lm(score ~ I((vocab.mean * 100)^2) * age + I(vocab.mean * 100),
#                          data = tmp.data)
# 
# 
# english.grammar.lm <- glm(score ~ I(vocab.mean * 100) + age,
#                          data = tmp.data,family="binomial")
# 
# english.grammar.lm2 <- lm(score ~ I((vocab.mean * 100)^2) * age + I(vocab.mean * 100),
#                          data = tmp.data)
# 
# tmp.data$predicted = inv.logit(predict.lm(english.grammar.lm,data=tmp.data))
# tmp.data$predicted2 = predict.lm(english.grammar.lm2,data=tmp.data)
# 
# tmp.data$predicted = inv.logit(predict.lm(english.grammar.lm,data=tmp.data))
# tmp.data$predicted2 = predict.lm(english.grammar.lm2,data=tmp.data)
# 
# cor.test(tmp.data$predicted,tmp.data$score)
# 
# english.grammar.lm2 <- glm(score ~ I(vocab.mean * 100)*age,
#                          data = filter(ms, language=="English",measure=="Complexity"),family="binomial")
# 
# english.grammar.lm2 <- glm(score ~ I((vocab.mean * 100)^2) * age + I(vocab.mean * 100),
#                          data = filter(ms, language=="English",measure=="Word Form"),family="binomial")
# 
# 
# english.grammar.lm.wf <- glm(score ~ I((vocab.mean * 100)^2) * age
#                          data = filter(ms, language=="English",measure=="Word Form"),family="binomial")
# 
# 
# danish.grammar.lm <- lm(score ~ I((vocab.mean * 100)^2) * age * measure + 0,
#                          data = filter(ms, language=="Norwegian"))
```


