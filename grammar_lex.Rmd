---
title: "Developmental Changes in the Relationship Between Grammar and the Lexicon"
author: "Mika Braginsky, Dan Yurovsky, Virginia Marchman, and Mike Frank"
date: "February 1, 2015"
output:
  html_document:
    highlight: tango
    theme: spacelab
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache=TRUE, message=FALSE, warning=FALSE)
```

***

## Data Loading

Load required libraries
```{r libraries,cache=FALSE}
#rm(list=ls())
library(ggplot2)
library(dplyr)
library(tidyr)
library(RMySQL)
library(stringr)
library(pcaPP)
library(directlabels)
library(proto)
#library(Unicode)
#library(RGtk2)
library(extrafont)
#font_import()
font = "Tahoma"
library(lme4)
```

Load in wordbank data
```{r database}
# RECOMPUTE

# open database connection
wordbank <- src_mysql(dbname="wordbank", host="54.149.39.46",
                      user="wordbank", password="wordbank")

# load tables
source.table <- tbl(wordbank, "common_source")
admin.table <- tbl(wordbank, "common_administration")
child.table <- tbl(wordbank, "common_child")
wordmapping.table <- tbl(wordbank, "common_wordmapping")
instruments.table <- tbl(wordbank, "common_instrumentsmap")
english.ws.table <- tbl(wordbank, "instruments_english_ws")
spanish.ws.table <- tbl(wordbank, "instruments_spanish_ws")
norwegian.ws.table <- tbl(wordbank, "instruments_norwegian_ws")
danish.ws.table <- tbl(wordbank, "instruments_danish_ws")
```

Get kid data and put together. 
```{r child_data}
# get administration info
admins <- admin.table %>%
  select(data_id,child_id,age,source_id) %>%
  rename(id = data_id, child.id = child_id, source.id = source_id) 
admins <- as.data.frame(admins)

# get demographic variables for each child
demos <- select(child.table,id,sex,mom_ed,birth_order) %>%
  rename(child.id = id) # Rename id fields
demos <- as.data.frame(demos)

# join administrations and demographics together
child.data <- as.tbl(left_join(admins,demos))
```

Set up mappings and instruments.
```{r item_data}
# RECOMPUTE
# get item info
mapping <- as.data.frame(wordmapping.table)

# get instrument info
instruments <- as.data.frame(instruments.table) %>%
  rename(instrument_id = id)

# join items and instruments together
items <- left_join(mapping, instruments)
```

Function for getting all of the data in wordbank for a given language (kid x item).
```{r}
get.language.data <- function(lang.table, lang.items, lang, child.data) {
  
  instrument.items <- lang.items %>% 
    filter(language == lang, form == 'WS') %>%
    select(item, type, category, lexical_category, definition, complexity_category) %>%
    mutate(item = str_replace(item, "\\.", "_")) # fix _/. inconsistencies
  
  instrument.data <- as.data.frame(lang.table) %>%
    rename(id = basetable_ptr_id) %>% # Rename the id
    gather(item, value, -id) %>% # Arrange in longform
    mutate(item = str_replace(item, "item_", "")) # Strip off item_ 
  
  d <- left_join(instrument.data, instrument.items)
  d <- left_join(d, child.data)
  }
```

Get (kid x item) data for all languages.
```{r}
# RECOMPUTE
d.english <- get.language.data(lang.table=english.ws.table, 
                               lang.items=items, 
                               lang="English",
                               child.data)

d.spanish <- get.language.data(lang.table=spanish.ws.table, 
                               lang.items=items, 
                               lang="Spanish",
                               child.data)

d.norwegian <- get.language.data(lang.table=norwegian.ws.table, 
                                 lang.items=items, 
                                 lang="Norwegian",
                                 child.data)

# Norwegian data is loaded in funny -- NAs in wordform are actually 0s
d.norwegian[d.norwegian$type %in% c("word_form","word")
            & is.na(d.norwegian$value),]$value = ""

d.danish <- get.language.data(lang.table=danish.ws.table, 
                              lang.items=items, 
                              lang="Danish",
                              child.data)

# Danish data is loaded in funny -- NAs in wordform are actually 0s
d.danish[d.danish$type %in% c("word_form","word")
         & is.na(d.danish$value),]$value = ""
```

Function for getting vocab size data.
```{r}
language.vocab.sizes <- function(lang.data) {
  d.vocab <- lang.data %>%
    filter(type == "word") %>%
    group_by(age,id) %>%
    summarise(vocab.sum = sum(value == "produces", na.rm=TRUE),
              vocab.mean = vocab.sum/length(value))
  
  return(d.vocab)
  }
```

***

## Syntax and Morphology Analyses

Function for getting (kid x {vocab size, syntax score, morphology score}) data.
```{r}
summarise.language.data <- function(lang.data,lang) {
  
  d.vocab <- language.vocab.sizes(lang.data)
  
  d.complexity <- lang.data %>%
    filter(type == "complexity") %>%
    group_by(id) %>%
    summarise(all.na = all(is.na(value)),
              complexity.sum = sum(value == "complex", 
                                   na.rm=TRUE) / length(value)) %>%
    mutate(complexity = ifelse(all.na,NA,complexity.sum)) %>%
    select(-all.na,-complexity.sum) # Deals with ifelse 
  
  d.wordform <- lang.data %>%
    filter(type == "word_form") %>%
    group_by(id) %>%
    summarise(all.na = all(is.na(value)),
              wordform.sum = sum(value == "produces", 
                                 na.rm=TRUE) / length(value)) %>%
    mutate(wordform = ifelse(all.na,NA,wordform.sum)) %>%
    select(-all.na,-wordform.sum) # Deals with ifelse 
  
  d.composite <- left_join(d.vocab, d.complexity)
  d.composite <- left_join(d.composite, d.wordform) %>%
      ungroup() %>%
      filter(age > 15 & age < 32) %>%
      mutate(age.group = cut(age, breaks = c(15, 19, 23, 27, 31)))

  d.composite$language <- lang
  
  return(d.composite)
  }
```

Get (kid x {vocab size, syntax score, morphology score}) data for all languages and aggregate them.
```{r}
summary.english <- summarise.language.data(d.english,"English")
summary.spanish <- summarise.language.data(d.spanish,"Spanish")
summary.norwegian <- summarise.language.data(d.norwegian,"Norwegian")
summary.danish <- summarise.language.data(d.danish,"Danish")
 
summary.data <- rbind_list(summary.english, summary.spanish,
                           summary.norwegian, summary.danish) %>%
  mutate(language = factor(language, levels=c("English", "Spanish", 
                                              "Norwegian", "Danish")))
# gather for plotting
ms <- summary.data %>% gather(measure, score, complexity:wordform) %>%
  mutate(measure = factor(measure, levels = c("wordform","complexity"),
                          labels = c("Word Form", "Complexity")))
```

Show number of kids in each language and age group.
```{r,results = 'asis'}
ns <- ms %>% 
  group_by(language, age.group) %>% 
  summarise(n = n())
kable(ns)
```

Fit a bunch of models to grammar data and do model comparison.
```{r}
linear <- formula(score ~ I(vocab.mean*100))
quadratic <- formula(score ~ I((vocab.mean*100)^2))
linear.quadratic <- formula(score ~ I((vocab.mean*100)^2) + I(vocab.mean*100))
linear.quadratic.age <- formula(score ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100))
linear.quadratic.age.noint <- formula(score ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0)
grammar.formulas <- c(linear, quadratic, linear.quadratic,
                      linear.quadratic.age, linear.quadratic.age.noint)

grammar.models <- ms %>%
  group_by(language, measure) %>%
  do(linear = lm(grammar.formulas[[1]], .),
     quadratic = lm(grammar.formulas[[2]], .),
     linear.quadratic = lm(grammar.formulas[[3]], .),
     linear.quadratic.age = lm(grammar.formulas[[4]], .),
     linear.quadratic.age.noint = lm(grammar.formulas[[5]], .)) %>%
  mutate(linear_rsq = summary(linear)$adj.r.squared,
         quadratic_rsq = summary(quadratic)$adj.r.squared,
         linear.quadratic_rsq = summary(linear.quadratic)$adj.r.squared,
         linear.quadratic.age_rsq = summary(linear.quadratic.age)$adj.r.squared,
         linear.quadratic.age.noint_rsq = summary(linear.quadratic.age.noint)$adj.r.squared)

grammar.anovas <- grammar.models %>%
  do(linear_quadratic_anova = anova(.$linear,
                                    .$quadratic),
     quadratic_linear.quadratic_anova = anova(.$quadratic,
                                              .$linear.quadratic),
     linear.quadratic_linear.quadratic.age_anova = anova(.$linear.quadratic,
                                                         .$linear.quadratic.age),
     linear.quadratic.age_linear.quadratic.age.noint_anova = anova(.$linear.quadratic.age,
                                                                   .$linear.quadratic.age.noint))

grammar.p_values <- grammar.anovas %>%
  do(linear_quadratic_p = .$linear_quadratic_anova$`Pr(>F)`[[2]],
     quadratic_linear.quadratic_p = .$quadratic_linear.quadratic_anova$`Pr(>F)`[[2]],
     linear.quadratic_linear.quadratic.age_p =
       .$linear.quadratic_linear.quadratic.age_anova$`Pr(>F)`[[2]],
     linear.quadratic.age_linear.quadratic.age.noint_p =
       .$linear.quadratic.age_linear.quadratic.age.noint_anova$`Pr(>F)`[[2]]) %>%
  mutate(linear_quadratic_p = log10(linear_quadratic_p[[1]]),
         quadratic_linear.quadratic_p = log10(quadratic_linear.quadratic_p[[1]]),
         linear.quadratic_linear.quadratic.age_p =
           log10(linear.quadratic_linear.quadratic.age_p[[1]]),
         linear.quadratic.age_linear.quadratic.age.noint_p =
           log10(linear.quadratic.age_linear.quadratic.age.noint_p[[1]]))
```

Show R-squared values of some models.
```{r,results = 'asis'}
display.models <- grammar.models %>% select(language, measure, linear.quadratic_rsq,
                                            linear.quadratic.age_rsq, linear.quadratic.age.noint_rsq)
kable(display.models)
```

Show the log p-values of the anova of successive pairs of models.
```{r,results = 'asis',cache=FALSE}
grammar.p_values$language = grammar.models$language
grammar.p_values$measure = grammar.models$measure
grammar.p_values <- grammar.p_values[,c(5,6,1:4)]
display.p_values <- grammar.p_values %>% select(language, measure, linear.quadratic_linear.quadratic.age_p, linear.quadratic.age_linear.quadratic.age.noint_p)
kable(display.p_values)
```

Fit grammar models and predict data.
```{r}
predicted.data <- as.data.frame(ms)
predicted.data$predicted <- NA
predicted.data$predicted.pin <- NA

for (lang in c("English", "Spanish", "Norwegian", "Danish")) {
  for (meas in c("Complexity", "Word Form")) {
    model <- lm(score ~ I((vocab.mean*100)^2) * age.group + I(vocab.mean*100),
                data=filter(ms,language==lang, measure==meas))
    pinned.model <- lm(score ~ I((vocab.mean*100)^2) * age.group + I(vocab.mean*100) - age.group + 0,
                data=filter(ms,language==lang, measure==meas))
#    print(anova(model, pinned.model))
    predicted.data[predicted.data$language==lang & predicted.data$measure==meas,]$predicted <- 
  predict.lm(model, predicted.data[predicted.data$language==lang & predicted.data$measure==meas,])
    predicted.data[predicted.data$language==lang & predicted.data$measure==meas,]$predicted.pin <- 
  predict.lm(pinned.model, predicted.data[predicted.data$language==lang & predicted.data$measure==meas,])
  }
}

# get.lm <- function(in.language, in.measure) {
#   return(filter(grammar.models, language==in.language,
#                 measure==in.measure)$quadratic.age.noint[[1]])
#   }
# 
# predict.data <- function(in.data, in.language, in.measure) {
#   model <- filter(grammar.models, language==in.language,
#                   measure==in.measure)$quadratic.age.noint[[1]]
#   out.data <- in.data %>%
#     filter(language==in.language, measure==in.measure) %>%
#     mutate(predicted = predict.lm(model, .))
#   return(out.data)
# }
# 
# nrow(filter(ms, language=="Spanish", measure=="Complexity"))
# nrow(predict.data(filter(ms, language=="Spanish", measure=="Complexity"), "Spanish", "Complexity"))
# 
# pre <- predict.data(ms, "English", "Complexity")
# 
# pred <- ms %>%
#   filter(language=="Spanish", measure=="Complexity") %>%
#   mutate(predicted = predict.lm(get.lm("Spanish", "Complexity"), .))
# #  group_by(language, measure) %>%
# #  mutate(predicted = predict.data(., language, measure))
# 
# pre <- as.data.frame(ms) %>%
#   group_by(language, measure) %>%
#   do(predicted = predict.lm(filter(grammar.models, language==.$language,
#                     measure==.$measure)$quadratic.age.noint[[1]], .))
#    model = filter(grammar.models, language==.$language,
#                    measure==.$measure)$quadratic.age.noint[[1]])
#    predicted = predict.lm(filter(grammar.models, .))
```

Plot score as a function vocabulary size for each language and measure with model prediction curves.
```{r,fig.width=8,fig.height=8}
predicted.data$language <- factor(predicted.data$language, levels = c("Norwegian", "English", "Danish", "Spanish"))
#quartz(width=6,height=6)
ggplot(predicted.data, aes(x = vocab.mean, y = score, 
                           colour = age.group, fill = age.group,
                           label = age.group)) + 
  geom_jitter(alpha=.3, size=.75) +
  geom_line(aes(y=predicted.pin),size=0.65) + 
#  facet_grid(measure~language) + 
  facet_grid(language~measure) + 
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.2),
                     name = "Vocabulary Size") + 
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,.25),
                     "Score (Mean Items)") + 
  theme_bw(base_size = 11) +
  theme(legend.position = c(0.06,0.912),
        legend.text = element_text(size=6),
        legend.title = element_text(size=6),
        legend.key.height = unit(0.75, "char"),
        legend.key.width = unit(0.4, "cm"),
        legend.key = element_blank(),
        legend.background = element_rect(fill="transparent"),
        text=element_text(family=font)) +
  scale_color_brewer(type="div", palette=9,
                     name="Age Group\n (months)") +
#                     labels=c("16-19","20-23","24-27","28-31")) +
  scale_fill_brewer(palette = "Spectral",
                    guide=FALSE)
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/grammar.png"), width=6, height=6, dpi=300)
```

Compute (vocab x age) interaction coefficients for each language and measure.
```{r}
mod.coef.fun <- function(score, vocab.mean, age) {
  return(coef(lm(score ~ I((vocab.mean * 100)^2) * age + I(vocab.mean * 100) + 0))["I((vocab.mean * 100)^2):age"])
  }

mod.rsq.fun <- function(score, vocab.mean, age) {
  return(summary(lm(score ~ I((vocab.mean * 100)^2) * age + I(vocab.mean * 100) + 0))$adj.r.squared)
  }

mod.se.fun <- function(score, vocab.mean, age) {
  return(summary(lm(score ~ I((vocab.mean*100)^2) * age + I(vocab.mean * 100) + 0))$coefficients["I((vocab.mean * 100)^2):age",
                                                                           "Std. Error"])
  }

grammar.coefs <- ms %>% 
  group_by(language, measure) %>%
  summarise(coef = mod.coef.fun(score, vocab.mean, age),
            se = mod.se.fun(score,vocab.mean,age),
            rsq = mod.rsq.fun(score,vocab.mean,age))
grammar.coefs$language = factor(grammar.coefs$language, levels=c("Norwegian", "English",
                                                                 "Danish", "Spanish"))
```

Plot age interaction coefficients for each language and measure.
```{r}
#quartz(width=6, height=4)
ggplot(grammar.coefs, 
       aes(x=language, y=coef, fill=measure)) + 
  geom_bar(position="dodge", stat="identity") + 
  geom_text(aes(label=paste(expression("italic(r)^2=="),round(rsq,2)), y=1.5e-7),
            position = position_dodge(width=0.9),
            size = 2.5, parse = TRUE, family=font) +
  geom_linerange(aes(ymin=coef-se, ymax=coef+se), 
                 position = position_dodge(width=.9)) +
  ylab("Age interaction coefficient") + 
  xlab("Language") +
  theme_bw(base_size = 14) +
  scale_fill_brewer(palette="Set2",
                    name="") +
  theme(legend.position = c(0.12,0.95),
        legend.text = element_text(size=10),
        legend.key.height = unit(1, "char"),
        legend.key.width = unit(0.4, "cm"),
        legend.key = element_blank(),
        legend.background = element_rect(fill="transparent"),
        text=element_text(family=font))
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/coefs_wordform_complexity.png"), width=6, height=4, dpi=300)
```

Get (kid x item x {vocab size, value}) data for wordform and complexity items.
```{r}
get.item.type <- function(type, complexity_category) {
  if(type == "complexity") {
    return(complexity_category)
  } else {
    return(type)
  }
}

grammar.by.item <- function(lang.data) {
  
  d.vocab <- language.vocab.sizes(lang.data)
  
  d.complexity <- lang.data %>%
    filter(type == "complexity") %>%
    mutate(value = value == "complex") %>%
    select(-lexical_category, -category)
  
  d.wordform <- lang.data %>%
    filter(type == "word_form") %>%
    mutate(value = value == "produces") %>%
    select(-lexical_category, -category)
  
  d.data <- rbind(d.complexity, d.wordform) %>%
    rowwise() %>%
    mutate(coded.type = get.item.type(type, complexity_category)) %>%
    select(-complexity_category)
  
  d.data <- left_join(d.vocab, d.data) %>%
    filter(age > 15, age < 32)
    
  return(d.data)
  }

english.grammar.by.item <- grammar.by.item(d.english)
spanish.grammar.by.item <- grammar.by.item(d.spanish)
norwegian.grammar.by.item <- grammar.by.item(d.norwegian)
danish.grammar.by.item <- grammar.by.item(d.danish)
```

Compute (vocab x age) interaction terms for each wordform and complexity item.
```{r,fig.height=5,fig.width=8}
#compute interaction terms each item
i.coef.function <- function(data, item.definition) {
  return(coef(lm(value ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0,
              data=filter(data, definition==item.definition)))["I((vocab.mean * 100)^2):age"][[1]])
  }

i.se.function <- function(data, item.definition) {
  return(summary(lm(value ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0,
                    data=filter(data, definition==item.definition)))$coefficients["I((vocab.mean * 100)^2):age", "Std. Error"])
  }

lang.interaction.terms <- function(grammar.by.item) {
  
  ctype.interaction.terms <- function(ctype) {
    
    if(ctype %in% grammar.by.item$coded.type) {
      
      ctype.data <- filter(grammar.by.item, coded.type==ctype)
      ctype.coef <- sapply(unique(ctype.data$definition),
                            function(definition) i.coef.function(ctype.data, definition))
      ctype.se <- sapply(unique(ctype.data$definition),
                            function(definition) i.se.function(ctype.data, definition))
      
      ctype.terms <- data.frame(coded.type = ctype,
                                definition = names(ctype.coef),
                                coef = ctype.coef,
                                se = ctype.se,
                                row.names=NULL) %>%
        rename(item = definition)
      ctype.terms$coded.type <- factor(ctype.terms$coded.type, levels = c("word_form", "morphology", "syntax"),
                                       labels = c("Word Form", "Complexity (Morphological)", "Complexity (Syntactic)"))
      
      return(ctype.terms)
      }
    }
  
  wordform.terms <- ctype.interaction.terms("word_form")
  morphology.terms <- ctype.interaction.terms("morphology")
  syntax.terms <- ctype.interaction.terms("syntax")
  
  lang.terms <- rbind_list(wordform.terms, morphology.terms, syntax.terms) %>%
    arrange(coef) %>%
    mutate(item = factor(item, levels=item))    
  
  return(lang.terms)
  
  }
  
english.interaction.terms <- lang.interaction.terms(english.grammar.by.item)
spanish.interaction.terms <- lang.interaction.terms(spanish.grammar.by.item)
norwegian.interaction.terms <- lang.interaction.terms(norwegian.grammar.by.item)
danish.interaction.terms <-  lang.interaction.terms(danish.grammar.by.item)
```

Function for plotting interaction terms by item for a language.
```{r}
interaction.plot <- function(lang.interaction.terms, language) {
  plt <- ggplot(lang.interaction.terms,
                aes(x=item, y=coef, fill=coded.type, label=item)) +
    geom_bar(stat="identity", position="identity", alpha=.5, width=0.9) +
    #    geom_text(y=0.15, angle=90, hjust=0, size=3.3, parse=F) +
    geom_linerange(aes(ymin=coef-se, ymax=coef+se),
                   position = position_dodge(width=.9)) +
    theme_bw(base_size = 12) +
    scale_y_continuous(name="Age Interaction Coefficient") +
    scale_x_discrete(name="",breaks=NULL) +
    annotate("text", x = length(lang.interaction.terms$item)/2, y = -1.3e-6,
             label = language, size = 9, family=font) +
    scale_fill_brewer(palette="Set2", name="Item Type") +
    theme(legend.position = c(0.15,0.85),
          legend.text = element_text(size=12),
          legend.title = element_text(size=12),
          legend.key = element_blank(),
          text = element_text(family=font))
  return(plt)
  }
```

Plot item interactions for English.
```{r,fig.width=10,fig.height=5}
#quartz(width=10, height=5)
interaction.plot(english.interaction.terms, "English")
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/english_interactions.png"), width=10, height=5)
```

Plot item interactions for Spanish.
```{r,fig.width=10,fig.height=5}
#quartz(width=10, height=5)
interaction.plot(spanish.interaction.terms, "Spanish") #%>%
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/spanish_interactions.png"), width=10, height=5)
```

Plot item interactions for Norwegian.
```{r,fig.width=10,fig.height=5}
#quartz(width=10, height=5)
interaction.plot(norwegian.interaction.terms, "Norwegian") #%>%
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/norwegian_interactions.png"), width=10, height=5)
```

Plot item interactions for Danish.
```{r,fig.width=10,fig.height=5}
#quartz(width=10, height=5)
interaction.plot(danish.interaction.terms, "Danish") #$>$
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/danish_interactions.png"), width=10, height=5)
```  


***

## Vocabulary Composition Analysis

Function for computing vocabulary composition for each speaker of a language.
```{r}
vocab.composition <- function(lang.data,lang) {  
  
  d.vocab <- language.vocab.sizes(lang.data)
  
  d.cat <- lang.data %>%
    filter(type == "word") %>%
    group_by(id,lexical_category) %>%
    summarise(cat = sum(value == "produces", na.rm=TRUE))
  
  d.vocab.comp <- left_join(d.vocab, d.cat) %>%
    mutate(prop = cat / vocab.sum)
  d.vocab.comp$language = lang
  
  return(d.vocab.comp)
  }
```

Function for computing CDI form composition for all languages.
```{r}
lang.vocab.composition <- function(lang.items) {  
  
  lang.words <- lang.items %>%
    filter(form == "WS",type=="word")
  
  lang.num.total <- lang.words %>%
    group_by(language) %>%
    summarise(n = n())
  
  lang.vocab.comp <-  lang.words %>%
    group_by(language,lexical_category) %>%
    summarise(num.per.cat = n())
  
  lang.vocab.comp <- left_join(lang.vocab.comp, lang.num.total) %>%
    mutate(prop.per.cat = num.per.cat/n)
  
  return(lang.vocab.comp)
  
  }
```

Get vocabulary composition data for all languages.
```{r}
# get form compositions
lang.vocab.comp <- lang.vocab.composition(items) %>%
  ungroup() %>%
  mutate(language = factor(language,
                           levels = c("English", "Spanish", 
                                      "Norwegian", "Danish")),
         lexical_category = factor(lexical_category, 
                                   levels=c("nouns","predicates",
                                            "function_words","other"),
                                   labels=c("Nouns", "Predicates",
                                            "Function Words","Other"))) %>%
  filter(lexical_category != "Other")
  

# get data for kids in each language
vocab.comp.english <- vocab.composition(d.english,"English")
vocab.comp.spanish <- vocab.composition(d.spanish,"Spanish")
vocab.comp.norwegian <- vocab.composition(d.norwegian,"Norwegian")
vocab.comp.danish <- vocab.composition(d.danish,"Danish")

# aggregate data for all languages together
summary.vocab.comp <- rbind_list(vocab.comp.english,vocab.comp.spanish,
                                 vocab.comp.norwegian,vocab.comp.danish) %>%
#  filter(age > 15 & age < 33) %>%
  mutate(#age.group = cut(age, breaks = c(15, 20, 24, 28, 32)),
         language = factor(language,
                           levels = c("English", "Spanish", 
                                      "Norwegian", "Danish")),
         lexical_category = factor(lexical_category, 
                                   levels = c("nouns", "predicates", 
                                              "function_words", "other"),
                                   labels = c("Nouns", "Predicates", 
                                              "Function Words", "Other")))
summary.vocab.comp <- left_join(ms, summary.vocab.comp)
```

Compute vocabulary composition data as a proportion of items on the CDI.
```{r}
prop.comp <- left_join(filter(summary.vocab.comp, lexical_category != "Other"),
                        lang.vocab.comp) %>%
  mutate(cdi.prop = cat / num.per.cat) %>%
  select(-prop, -prop.per.cat, -n, -num.per.cat)
prop.comp$language <- factor(prop.comp$language, levels = c("Norwegian", "English",
                                                            "Danish", "Spanish"))
```

Plot vocabulary composition by language.
```{r, fig.width=10, fig.height=2.9}
#quartz(width=10, height=2.9)
ggplot(filter(prop.comp, lexical_category != "Other"),
       aes(x=vocab.mean, y=cdi.prop, colour=lexical_category, label=lexical_category)) +
  geom_jitter(alpha=0.15, size=.75) +
  facet_wrap(~ language, nrow = 1, ncol = 4,) +
#  geom_smooth(aes(group=lexical_category), method='loess', span=0.5, size=0.65) +
  scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
                     name = "Proportion of CDI Category") +
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.2),
                     name = "Vocabulary Size") +
  theme_bw(base_size=12) + 
  scale_color_brewer(palette = "Set2", name = "Lexical Category") +
  theme(legend.position = c(0.055,0.82),
        legend.text = element_text(size=7),
        legend.title = element_text(size=8),
        legend.key.height = unit(0.9, "char"),
        legend.key.width = unit(0.3, "cm"),
        legend.key = element_blank(),
        legend.background = element_rect(fill="transparent"),
        text = element_text(family=font))
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/composition.png"), width=10, height=2.9, dpi=300)
```

Re-compute vocab composition in terms of nouns and verbs.
```{r}
get.pos <- function(lex_cat, cat) {
  if(lex_cat == "nouns"){
    return("nouns")
    } else if (cat == "action_words"){
      return("verbs")
      } else {
        return("other")
        }
  }

noun.verb.comp <- function(lang.data,lang) {  
    
  lang.data <- lang.data %>%
    rowwise() %>%
    mutate(pos = get.pos(lexical_category, category))
  
  d.vocab <- language.vocab.sizes(lang.data)
  
  d.pos <- lang.data %>%
    filter(type == "word") %>%
    group_by(id, pos) %>%
    summarise(pos.size = sum(value == "produces", na.rm=TRUE))
  
  d.vocab.comp <- left_join(d.vocab, d.pos)
  d.vocab.comp$language = lang
  
  return(d.vocab.comp)
  }

# get data for kids in each language
noun.verb.english <- noun.verb.comp(d.english,"English")
noun.verb.spanish <- noun.verb.comp(d.spanish,"Spanish")
noun.verb.norwegian <- noun.verb.comp(d.norwegian,"Norwegian")
noun.verb.danish <- noun.verb.comp(d.danish,"Danish")

# aggregate data for all languages together
summary.noun.verb <- rbind_list(noun.verb.english, noun.verb.spanish,
                                 noun.verb.norwegian, noun.verb.danish) %>%
  mutate(language = factor(language,
                           levels = c("English", "Spanish", 
                                      "Norwegian", "Danish")),
         pos = factor(pos, 
                      levels = c("nouns", "verbs", "other"),
                      labels = c("Nouns", "Verbs", "Other")))
summary.noun.verb <- left_join(ms, summary.noun.verb) %>%
  filter(pos != "Other")

get.lang.noun.verb <- function(lang.items) {  
  
  lang.words <- lang.items %>%
    filter(form == "WS", type=="word") %>%
    rowwise() %>%
    mutate(pos = get.pos(lexical_category, category))
  
  lang.noun.verb <- lang.words %>%
    group_by(language, pos) %>%
    summarise(num.per.pos = n())
    
  return(lang.noun.verb)
  
  }

lang.noun.verb <- get.lang.noun.verb(items)
lang.noun.verb %<>%
  ungroup() %>%
  mutate(language = factor(language,
                           levels = c("English", "Spanish", 
                                      "Norwegian", "Danish")),
         pos = factor(pos, 
                      levels=c("nouns", "verbs", "other"),
                      labels=c("Nouns", "Verbs", "Other"))) %>%
  filter(pos != "Other")

prop.noun.verb <- left_join(summary.noun.verb, lang.noun.verb) %>%
  mutate(pos.prop = pos.size / num.per.pos)
```

Compute coefficients of noun/verb models.
```{r}
#TODO: model comparison
prop.mod.coef.fun <- function(pos.prop, vocab.mean, age) {
#  return(coef(lm(pos.prop ~ I((vocab.mean*100)^2) + I(vocab.mean*100) * age + 0))["I(vocab.mean * 100):age"])
  return(coef(glm(pos.prop ~ I(vocab.mean*100) * age + 0,
                  family="binomial"))["I(vocab.mean * 100):age"])
  }

# prop.mod.rsq.fun <- function(pos.prop, vocab.mean, age) {
#   return(summary(glm(pos.prop ~ I(vocab.mean*100) * age + 0,
#                   family="binomial"))$adj.r.squared)
#   }

prop.mod.se.fun <- function(pos.prop, vocab.mean, age) {
  return(summary(glm(pos.prop ~ I(vocab.mean*100) * age + 0,
                     family="binomial"))$coefficients["I(vocab.mean * 100):age", "Std. Error"])
  }

#TODO: what metric to use instead of r-squared?
noun.verb.coefs <- prop.noun.verb %>%
  group_by(language, pos) %>%
  summarise(coef = prop.mod.coef.fun(pos.prop, vocab.mean, age),
#            rsq = prop.mod.rsq.fun(pos.prop, vocab.mean, age),
            se = prop.mod.se.fun(pos.prop, vocab.mean, age))
noun.verb.coefs$language <- factor(noun.verb.coefs$language, levels = c("Norwegian",
                                                                        "English",
                                                                        "Danish",
                                                                        "Spanish"))
```

Plot noun/verb coefficients.
```{r}
#quartz(width=6, height=4)
ggplot(noun.verb.coefs, 
       aes(x=language, y=coef, fill=pos)) + 
  geom_bar(position="dodge", stat="identity") + 
#  geom_text(aes(label=paste(expression("R^2=="),round(rsq,2)), y=1.5e-7),
#            position = position_dodge(width=0.9),
#            size = 2.5, parse = TRUE) +
  geom_linerange(aes(ymin=coef-se, ymax=coef+se), 
                 position = position_dodge(width=.9)) +
  ylab("Age interaction coefficient") + 
  xlab("Language") +
  theme_bw(base_size = 14) +
  scale_fill_brewer(palette = "Set2",
                    name = "") +
  theme(legend.position = c(0.07,0.95),
        legend.text = element_text(size=10),
        legend.key.height = unit(0.9, "char"),
        legend.key.width = unit(0.4, "cm"),
        legend.key = element_blank(),
        legend.background = element_rect(fill="transparent"),
        text = element_text(family=font))
#ggsave(file=("~/Documents/projects/cdi-grammar/cogsci_paper/plots/coefs_noun_verb.png"), width=6, height=4)
```

Fit mixed-effects models of kid-word production.
```{r}
# d.vocab <- language.vocab.sizes(d.english)
# d.english.vocab <- left_join(d.english, d.vocab) %>%
#   filter(age >= 16, age <= 30) %>%
#   rowwise() %>%
#   mutate(pos = get.pos(lexical_category, category)) %>%
#   filter(pos != "other") %>%
#   mutate(produces = value=="produces")

#TODO: models that converge
# big.lm.nouns <- glmer(produces ~ I(vocab.mean*100)*age + 0 + (1|id) + (1|item),
#                       family="binomial",
#                       data=filter(d.english.vocab,pos=="nouns"))
# animal.lm <- glmer(produces ~ I(vocab.mean*100)*age + 0 + (1|item), family="binomial",
#                    data=filter(d.english.vocab,pos=="nouns",category=="animals"))
# 
# big.lm.verbs <- glmer(produces ~ I(vocab.mean*100)*age + 0 + (1|id) + (1|item), family="binomial",
#                       data=filter(d.english.vocab,pos=="verbs"))
```
***

## Extra analyses/plots that are not in the paper

Using Age and Vocab to predict Morphology and Syntax Scores.
```{r, fig.width=12, fig.height=8}
#quartz(width=8,height=7.5)
#ggplot(ms, aes(x = vocab.mean, y = score, colour = age.group, fill = age.group,
#               label = age.group)) + 
# ggplot(ms, aes(x = vocab.mean, y = score, colour = age.bin, fill = age.bin,
#                label = age.bin)) + 
#   #geom_point(alpha=.5, size=.8) + 
#   geom_jitter(alpha=.6, ssize=.8) +
#   geom_smooth(method="lm", formula = y ~ I(x^2) - 1) + 
#   facet_grid(language~measure) + 
#   scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.1),
#                      name = "Vocabulary Size") + 
#   scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
#                      "Score (Mean Items)") + 
#   theme_bw(base_size = 14) +
#   scale_color_brewer(palette="Set1") +
#   scale_fill_brewer(palette="Set1") 
```

Plot vocabulary composition by language.
```{r, fig.width=10, fig.height=8}
# ggplot(filter(summary.vocab.comp,lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour=lexical_category, 
#            shape = lexical_category, fill = lexical_category,
#            label=lexical_category)) +
#   geom_point(size = 1, alpha = 0.25) +
#   facet_wrap(~ language) +
#   geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of total vocabulary") +
#   scale_x_continuous(name = "Vocabulary Size") +
#   geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Spectral") +
#   scale_fill_brewer(palette = "Spectral")+
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="none",
#         text = element_text(family=font))
```

Plot vocabulary composition by language and age group.
```{r, fig.width=10, fig.height=8}
# ggplot(filter(summary.vocab.comp,lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour=lexical_category, 
#            shape = lexical_category, fill = lexical_category,
#            label = lexical_category)) +
#   geom_jitter(size = 1, alpha = 0.5) +
#   facet_grid(language ~ age.group) +
#   geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of total vocabulary") +
#   scale_x_continuous(name = "Vocabulary Size") +
#   geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1") +
#   scale_fill_brewer(palette = "Set1")+
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="none")
```

Plot vocabulary composition by language, split by age group.
```{r, fig.width=10, fig.height=8}
#quartz(width=7, height=6)
# ggplot(filter(summary.vocab.comp, lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour=age.group, linetype = lexical_category)) +
# #  geom_jitter(size = 1, alpha = 0.5) +
#   facet_wrap(~ language) +
#   geom_hline(data=lang.vocab.comp, 
#              aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(method='loess', span=.5) +
#   scale_x_continuous(limits = c(0, 1), breaks = seq(0,1,.2),
#                      name = "Vocabulary Size") + 
#   scale_y_continuous(limits = c(0, .6), breaks = seq(0,1,.2),
#                      "Proportion of total vocabulary") + 
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1", name = "Age Group (months)") +
#   scale_fill_brewer(palette = "Set1") +
#   scale_linetype(name = "Lexical Category") +
#   theme(#axis.text.x = element_text(angle=-40, hjust = 0),
# #        axis.title.y = element_text(vjust=0.35),
# #        axis.title.x = element_text(vjust=-0.5),
#         legend.position="bottom")
#ggsave(file=("age_composition.pdf"), width=7, height=6)
```

Plot vocabulary composition by language and lexical category.
```{r, fig.width=10, fig.height=8}
#quartz(width=8, height=6)
# ggplot(filter(summary.vocab.comp, lexical_category != "Other"),
#        aes(x=vocab.mean, y=prop, colour = age.group, fill = age.group)) +
# #  geom_jitter(size = 1, alpha = 0.5) +
#   facet_grid(language ~ lexical_category) +
#   geom_hline(data=lang.vocab.comp, 
#              aes(yintercept=prop.per.cat),
#              linetype="dashed", color="grey") + #baselines for each language
#   geom_smooth(aes(group=age.group), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of total vocabulary") +
#   scale_x_continuous(name = "Vocabulary Size") +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1") +
#   scale_fill_brewer(palette = "Set1")+
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="none")
#ggsave(file=("age_composition.pdf"), width=8, height=6)
```

Use Age and Lexical Category Score to predict Morphology and Syntax Scores, for each lexical category.
```{r}
# plot.vocab.comp.prediction <- function(category) {
#   p <- ggplot(filter(prop.comp, lexical_category==category),
#               aes(x = cdi.prop, y = score, colour = age.group, fill = age.group,
#                   label = age.group)) + 
#         #geom_point(alpha=.5, size=.8) + 
#     geom_jitter(alpha=.5,size=.8) +
#     geom_smooth(method="lm", formula = y ~ I(x^2) - 1) + 
#     facet_grid(language ~ measure) + 
#     scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.1),
#                        name = "Category Size") + 
#     scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
#                        "Score (Mean Items)") + 
#     theme_bw(base_size = 14) +
#     ggtitle(category) +
#     scale_color_brewer(palette="Set1") +
#     scale_fill_brewer(palette="Set1") 
#   
#   return(p)
# }
```

```{r, fig.width=10, fig.height=8}
#plot.vocab.comp.prediction("Nouns")
```

```{r, fig.width=10, fig.height=8}
#plot.vocab.comp.prediction("Predicates")
```

```{r, fig.width=10, fig.height=8}
#plot.vocab.comp.prediction("Function Words")
```

Fit models to vocab composition data.
```{r}
# comp.lm <- function(lang) {
#   
#   prop.comp.lang <- filter(prop.comp, language == lang, lexical_category != "Other")
#   comp.age.lm <- lm(cdi.prop ~ lexical_category : I((vocab.mean*100)^2):age.group +
#                            lexical_category : I((vocab.mean*100)):age.group + 0,
#                          data=prop.comp.lang)
#   comp.noage.lm <- lm(cdi.prop ~ lexical_category : I((vocab.mean*100)^2) + 
#                            lexical_category : I((vocab.mean*100)) + 0,
#                          data=prop.comp.lang)
#   prop.comp.lang$age.predict <- predict.lm(comp.age.lm)
#   prop.comp.lang$noage.predict <- predict.lm(comp.noage.lm)
#   prop.comp.lang$language <- lang
#   return(prop.comp.lang)
#   }
# 
# comp.english <- comp.lm("English")
# comp.spanish <- comp.lm("Spanish")
# comp.norweigian <- comp.lm("Norwegian")
# comp.danish <- comp.lm("Danish")
# 
# comp.all <- rbind(comp.english, comp.spanish, comp.norweigian, comp.danish) %>%
#   mutate(language = factor(language,
#                            levels = c("English", "Spanish", "Norwegian", "Danish")))
```

Plot predictions of model with age.
```{r, fig.width=10, fig.height=6}
#quartz(width=10, height=6)
# ggplot(comp.all,
#        aes(x=vocab.mean, y=cdi.prop, colour=age.group, linetype=lexical_category)) +
# #       aes(x=vocab.mean, y=cdi.prop, colour=lexical_category, 
# #           shape=lexical_category, fill=lexical_category,
# #           label=lexical_category)) +
# #  geom_jitter(size=0.7, alpha=0.2, pch="o") +
#   geom_line(aes(y = age.predict)) +
#   facet_wrap(~language) +
# #  geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
# #             linetype="dashed", color="grey") + #baselines for each language
#   #geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of CDI Category") +
#   scale_x_continuous(name = "Vocabulary Size") +
# #  geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1", name = "Age Group (months)") +
#   scale_linetype(name = "Lexical Category") +
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="right")
#ggsave(file=("composition_model_age_points.png"), width=10, height=6)
```

Plot predictions of model without age.
```{r, fig.width=10, fig.height=8}
#quartz(width=10, height=6)
# ggplot(comp.all,
#        aes(x=vocab.mean, y=cdi.prop, colour=age.group, linetype=lexical_category)) +
# #       aes(x=vocab.mean, y=cdi.prop, colour=lexical_category, 
# #           shape=lexical_category, fill=lexical_category,
# #           label=lexical_category)) +
# #  geom_jitter(size=0.7, alpha=0.2, pch="o") +
#   geom_line(aes(y = noage.predict)) +
#   facet_wrap(~language) +
# #  geom_hline(data=lang.vocab.comp,aes(yintercept=prop.per.cat),
# #             linetype="dashed", color="grey") + #baselines for each language
#   #geom_smooth(aes(group=lexical_category), method='loess', span=0.5) +
#   scale_y_continuous(name = "Proportion of CDI Category") +
#   scale_x_continuous(name = "Vocabulary Size") +
# #  geom_dl(aes(label=lexical_category), method=list("smart.grid")) +
#   theme_bw(base_size=14) + 
#   scale_color_brewer(palette = "Set1", name = "Age Group (months)") +
#   scale_linetype(name = "Lexical Category") +
#   theme(axis.text.x = element_text(angle=-40, hjust = 0),
#         axis.title.y = element_text(vjust=0.35),
#         axis.title.x = element_text(vjust=-0.5),
#         legend.position="right")
#ggsave(file=("composition_model_age_points.png"), width=10, height=6)
```

Compute (vocab x age) interaction coefficients for each lexical category and language.
```{r}
# quad.mod.coef.fun <- function(cdi.prop, vocab.mean, age) {
#   return(coef(lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0))["I((vocab.mean * 100))^2:age"])
#   }
# 
# quad.mod.se.fun <- function(cdi.prop, vocab.mean, age) {
#   return(summary(lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0))$coefficients["I((vocab.mean * 100))^2:age", "Std. Error"])
#   }
# 
# compute.model <- function(cdi.prop, vocab.mean, age) {
#   return(lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) + 0))
# }
# 
# #comp.coefs <- prop.comp %>% 
# #  group_by(language, lexical_category) %>%
# #  do(model = lm(.$cdi.prop ~ I((.$vocab.mean*100)^2) * .$age + 
# #                  I(.$vocab.mean*100) + 0)[[1]]) %>%
# #  mutate(coef = coef(model)["I((.$vocab.mean * 100)^2):.$age"],
# #         s = summary(model)$coefficients),
# #         se = summary(model)$coefficients["I((.$vocab.mean * 100)^2):.$age", "Std. Error"])
# 
# comp.coefs <- prop.comp %>%
#   group_by(language, lexical_category) %>%
#   summarise(#coef = coef(model)["I((vocab.mean * 100)^2):age"]),
#             #se = summary(model)$coefficients["I((vocab.mean * 100)^2):age", "Std. Error"])
#             coef = mod.coef.fun(cdi.prop, vocab.mean, age),
#             se = mod.se.fun(cdi.prop, vocab.mean, age))
# 
# #linear(vocab)
# #linear(vocab)*age
# #linear(vocab)*age + quadratic(vocab)
# #linear(vocab)*age + quadratic(vocab)*age
# #linear(vocab) + quadratic(vocab)*age
# 
# model1 <- lm(cdi.prop ~ I((vocab.mean*100)^2) * age + I(vocab.mean*100) * age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model2 <- lm(cdi.prop ~ I((vocab.mean*100)^2) + I(vocab.mean*100) * age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model3 <- lm(cdi.prop ~ I((vocab.mean*100)^2)*age + I(vocab.mean*100) + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model4 <- lm(cdi.prop ~ I((vocab.mean*100)^2) + I(vocab.mean*100) + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model5 <- lm(cdi.prop ~ I((vocab.mean*100)^2)*age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
# 
# model6 <- lm(cdi.prop ~ I((vocab.mean*100)^2):age + 0,
#         data=filter(prop.comp, language=='English', lexical_category=='Nouns'))
```

Plot coefficients for each language.
```{r}
#quartz(width=6, height=4)
# ggplot(comp.coefs, 
#        aes(x=language, y=coef, fill=lexical_category)) + 
#   geom_bar(position="dodge", stat="identity") + 
#   geom_linerange(aes(ymin=coef-se, ymax=coef+se), 
#                  position = position_dodge(width=.9)) +
#   ylab("Age interaction coefficient") + 
#   xlab("Language") +
#   theme(legend.position = "bottom") +
#   theme_bw(base_size = 14) +
#   scale_fill_brewer(palette = "Set1",
#                     name="")
#ggsave(file=("coeffs.pdf"), width=6, height=4)
```

Plot noun/verb composition.
```{r, fig.width=10, fig.height=8}
#quartz(width=8, height=6)
# ggplot(prop.noun.verb, aes(x=vocab.mean, y=pos.prop, colour=pos, label=pos)) +
#   geom_jitter(alpha=0.17, size=0.75) +
#   facet_wrap(~ language) +
#   geom_smooth(aes(group=pos), method='loess', span=0.5) +
#   scale_y_continuous(limits = c(0, 1.05), breaks = seq(0,1,.2),
#                      name = "Proportion of Part of Speech") +
#   scale_x_continuous(limits = c(0,1), breaks = seq(0,1,.1),
#                      name = "Vocabulary Size") +
#   theme_bw(base_size=11) + 
#   scale_color_brewer(palette = "Set1", name = "Lexical Category") +
#   theme(legend.position = c(0.09,0.92),
#         legend.text = element_text(size=9),
#         legend.title = element_text(size=9),
#         legend.key.height = unit(0.9, "char"),
#         legend.key.width = unit(0.4, "cm"),
#         legend.key = element_blank(),
#         legend.background = element_rect(fill="transparent"))
#ggsave(file=("~/Documents/projects/wordbank_nsf/figures/composition.png"), width=8, height=6, dpi=500)
```

```{r}
# complexity.diff <- function(item) {
#   
#   if(length(grep("/", item)) == 0) {return(item)}
#   else{
#     phrases <- str_split(item," / ")[[1]]
#     first.phrase <- str_split(phrases[1], " ")[[1]]
#     second.phrase <- str_split(phrases[2], " ")[[1]]
#   
#     first.diff <- setdiff(first.phrase,second.phrase)
#     second.diff <- setdiff(second.phrase,first.phrase)
#   
#     if(length(first.diff)==0) return(paste(second.diff,collapse=" ")) 
#     else if(length(second.diff)==0) return(paste(first.diff,collapse=" "))
#     else{first.phrase = paste(first.diff, collapse =" ")
#          second.phrase = paste(second.diff,collapse = " ")
#          return(paste(first.phrase, second.phrase ,sep=" / "))}
#     }
#   }
```